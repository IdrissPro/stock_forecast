{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modèle GINN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dans ce notebook, on s'intéresse à l'amélioration éventuelle des performances d'un LSTM classique à l'aide du modèle GINN présenté dans le papier: https://arxiv.org/pdf/2410.00288 \\\n",
        "Nous utilisons ici également les rendements logarithmiques. \\\n",
        "L'architecture GINN que nous avons choisie est similaire à celle du papier: \n",
        "un modèle GARCH (1,1) avec moyenne constante qui nous fournit des prédictions de volatilité et de moyenne \\\n",
        "un calcul de la \"vraie\" volatilité à partir de la moyenne calculée par le modèle GARCH \\\n",
        "un modèle LSTM qui effectue des prédictions de volatilité à partir des \"vraies\" volatilités et de la volatilité prédite par le GARCH en utilisant une fonction de coût customisée \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkDUOQyYjcwo",
        "outputId": "ffbcb427-f074-4440-eca5-8571f55c9853"
      },
      "outputs": [],
      "source": [
        "\n",
        "from arch import arch_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jjH5zqCza5Je"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.keras import layers, models,Input,regularizers\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chargement des données et division train/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWeNiWt1a5Jg"
      },
      "outputs": [],
      "source": [
        "def load_data(symbol=\"SPY\", start=\"1994-01-01\", end=\"2021-01-01\", interval='1d'): #1 donnée=1jour\n",
        "    df = yf.download(symbol, start=start, end=end, interval=interval)\n",
        "    df.reset_index(inplace=True)\n",
        "    return df\n",
        "\n",
        "def preprocess_data(df):\n",
        "    df = df[['Date', 'Close']]\n",
        "    df.dropna(inplace=True)\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "    df.set_index('Date', inplace=True)\n",
        "    return df\n",
        "\n",
        "def train_test(list_df, train_size=0.7, test_size=0.3):\n",
        "    result = []\n",
        "    for df in list_df:\n",
        "        X = df.index.values.reshape(-1, 1)\n",
        "        y = df['Close'].values\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, train_size=train_size, test_size=test_size, shuffle=False\n",
        "        )\n",
        "        result.append([X_train, X_test, y_train, y_test])\n",
        "    return result\n",
        "\n",
        "def etl_pipeline(train_size=0.7, test_size=0.3):\n",
        "    # Chargement\n",
        "    gspc = load_data('^GSPC')\n",
        "    dji = load_data('^DJI')\n",
        "    nyse = load_data('^NYA')\n",
        "\n",
        "    # Preprocess\n",
        "    gspc_close = preprocess_data(gspc)\n",
        "    dji_close = preprocess_data(dji)\n",
        "    nyse_close = preprocess_data(nyse)\n",
        "\n",
        "    list_df_close = [gspc_close, dji_close, nyse_close]\n",
        "\n",
        "    # Pour faire le split et shift la data de 90 jours\n",
        "    def train_test_shift(df, train_size, shift_days=90):\n",
        "        # Split \n",
        "        train_size = int(len(df) * train_size)\n",
        "        X_train = df.iloc[:train_size]\n",
        "        X_test = df.iloc[train_size:]\n",
        "\n",
        "        # Shift \n",
        "        y_train = df.iloc[shift_days:train_size + shift_days]\n",
        "        y_test = df.iloc[train_size + shift_days:]\n",
        "\n",
        "        X_train = X_train.iloc[:-shift_days]\n",
        "        X_test = X_test.iloc[:-shift_days]\n",
        "\n",
        "        return X_train, X_test, y_train, y_test\n",
        "\n",
        "    # Appliquer train_test_shift à tous les dataframes\n",
        "    splits = [train_test_shift(df, train_size) for df in list_df_close]\n",
        "\n",
        "    return {\n",
        "        \"GSPC\": {\"X_train\": splits[0][0], \"X_test\": splits[0][1], \"y_train\": splits[0][2], \"y_test\": splits[0][3]},\n",
        "        \"DJI\":  {\"X_train\": splits[1][0], \"X_test\": splits[1][1], \"y_train\": splits[1][2], \"y_test\": splits[1][3]},\n",
        "        \"NYSE\": {\"X_train\": splits[2][0], \"X_test\": splits[2][1], \"y_train\": splits[2][2], \"y_test\": splits[2][3]},\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous avons choisi 90 jours de shift comme dans l'article"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KG_lL4l2a5Jh",
        "outputId": "c1212ada-ee13-41ee-c50d-3ca8e4896c77"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "gspc=load_data('^GSPC')\n",
        "dji=load_data('^DJI')\n",
        "nyse=load_data('^NYA')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46n6Z86va5Ji",
        "outputId": "a53edd8d-665d-41b8-f4c3-5e950cc45b02"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\idris\\AppData\\Local\\Temp\\ipykernel_16460\\3817609216.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.dropna(inplace=True)\n",
            "C:\\Users\\idris\\AppData\\Local\\Temp\\ipykernel_16460\\3817609216.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Date'] = pd.to_datetime(df['Date'])\n",
            "C:\\Users\\idris\\AppData\\Local\\Temp\\ipykernel_16460\\3817609216.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.dropna(inplace=True)\n",
            "C:\\Users\\idris\\AppData\\Local\\Temp\\ipykernel_16460\\3817609216.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Date'] = pd.to_datetime(df['Date'])\n",
            "C:\\Users\\idris\\AppData\\Local\\Temp\\ipykernel_16460\\3817609216.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.dropna(inplace=True)\n",
            "C:\\Users\\idris\\AppData\\Local\\Temp\\ipykernel_16460\\3817609216.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Date'] = pd.to_datetime(df['Date'])\n"
          ]
        }
      ],
      "source": [
        "gspc_close=preprocess_data(gspc)\n",
        "dji_close=preprocess_data(dji)\n",
        "nyse_close=preprocess_data(nyse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuD5Zwtqa5Jj",
        "outputId": "814eb782-716a-4340-fa6e-23f28f08da71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Price             Close\n",
            "Ticker            ^GSPC\n",
            "Date                   \n",
            "1994-01-03   465.440002\n",
            "1994-01-04   466.890015\n",
            "1994-01-05   467.549988\n",
            "1994-01-06   467.119995\n",
            "1994-01-07   469.899994\n",
            "...                 ...\n",
            "2020-12-24  3703.060059\n",
            "2020-12-28  3735.360107\n",
            "2020-12-29  3727.040039\n",
            "2020-12-30  3732.040039\n",
            "2020-12-31  3756.070068\n",
            "\n",
            "[6799 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "print(gspc_close)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxRKgBdda5Jk",
        "outputId": "b63e12b9-3683-49cd-97ed-f4007e7b0ef8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "C:\\Users\\idris\\AppData\\Local\\Temp\\ipykernel_16460\\3817609216.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.dropna(inplace=True)\n",
            "C:\\Users\\idris\\AppData\\Local\\Temp\\ipykernel_16460\\3817609216.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Date'] = pd.to_datetime(df['Date'])\n",
            "C:\\Users\\idris\\AppData\\Local\\Temp\\ipykernel_16460\\3817609216.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.dropna(inplace=True)\n",
            "C:\\Users\\idris\\AppData\\Local\\Temp\\ipykernel_16460\\3817609216.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Date'] = pd.to_datetime(df['Date'])\n",
            "C:\\Users\\idris\\AppData\\Local\\Temp\\ipykernel_16460\\3817609216.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.dropna(inplace=True)\n",
            "C:\\Users\\idris\\AppData\\Local\\Temp\\ipykernel_16460\\3817609216.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Date'] = pd.to_datetime(df['Date'])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "result = etl_pipeline()\n",
        "\n",
        "# pour GSPC\n",
        "X_gspc_train = result[\"GSPC\"][\"X_train\"]\n",
        "X_gspc_test  = result[\"GSPC\"][\"X_test\"]\n",
        "y_gspc_train = result[\"GSPC\"][\"y_train\"]\n",
        "y_gspc_test  = result[\"GSPC\"][\"y_test\"]\n",
        "\n",
        "# pour DJI \n",
        "X_dji_train = result[\"DJI\"][\"X_train\"]\n",
        "X_dji_test  = result[\"DJI\"][\"X_test\"]\n",
        "y_dji_train = result[\"DJI\"][\"y_train\"]\n",
        "y_dji_test  = result[\"DJI\"][\"y_test\"]\n",
        "\n",
        "# pour NYSE\n",
        "X_nyse_train = result[\"NYSE\"][\"X_train\"]\n",
        "X_nyse_test  = result[\"NYSE\"][\"X_test\"]\n",
        "y_nyse_train = result[\"NYSE\"][\"y_train\"]\n",
        "y_nyse_test  = result[\"NYSE\"][\"y_test\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ds0P4PDXq9I9",
        "outputId": "c2c6611f-2bfd-4bd2-c482-791cb418a78e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Price              Close\n",
            "Ticker              ^DJI\n",
            "Date                    \n",
            "1994-01-03   3756.600098\n",
            "1994-01-04   3783.899902\n",
            "1994-01-05   3798.820068\n",
            "1994-01-06   3803.879883\n",
            "1994-01-07   3820.770020\n",
            "...                  ...\n",
            "2012-07-10  12653.120117\n",
            "2012-07-11  12604.530273\n",
            "2012-07-12  12573.269531\n",
            "2012-07-13  12777.089844\n",
            "2012-07-16  12727.209961\n",
            "\n",
            "[4669 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "print(X_dji_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeXGQc_ka5Jl",
        "outputId": "2847daa9-3d85-44b8-91df-6278f287ef7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Price              Close\n",
            "Ticker              ^DJI\n",
            "Date                    \n",
            "1994-05-12   3652.840088\n",
            "1994-05-13   3659.679932\n",
            "1994-05-16   3671.500000\n",
            "1994-05-17   3720.610107\n",
            "1994-05-18   3732.889893\n",
            "...                  ...\n",
            "2013-04-01  14572.849609\n",
            "2013-04-02  14662.009766\n",
            "2013-04-03  14550.349609\n",
            "2013-04-04  14606.110352\n",
            "2013-04-05  14565.250000\n",
            "\n",
            "[4759 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "print(y_dji_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqn0aYM1a5Jm"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "# pour calculer les log returns\n",
        "def calculate_log_returns(prices):\n",
        "    return np.log(prices + 1e-8 / prices.shift(1) +1e-8).fillna(0)\n",
        "\n",
        "#Fonction qui permet de calculer les moyennes et volatilités selon le modèle GARCH (1,1) à moyenne constante\n",
        "def garch_predictions(prices_series, forecast_horizon=1):\n",
        "    mean_predictions = []\n",
        "    volatility_predictions = []\n",
        "    prediction_dates = []\n",
        "    true_volatility = []\n",
        "\n",
        "    prices_series = prices_series.sort_index()\n",
        "\n",
        "    # Calculer log returns et scale\n",
        "    log_returns = calculate_log_returns(prices_series) * 100  # Scaling\n",
        "\n",
        "    # Check d'erreur:\n",
        "    if np.all(log_returns == log_returns.iloc[0]):\n",
        "        raise ValueError(\"Log returns are constant. Check the input data.\")\n",
        "\n",
        "    adf_result = adfuller(log_returns.dropna())\n",
        "    print(f\"ADF Statistic: {adf_result[0]}\")\n",
        "    print(f\"p-value: {adf_result[1]}\")\n",
        "\n",
        "    if adf_result[1] > 0.05:\n",
        "        print(\"Warning: Log returns may not be stationary.\")\n",
        "\n",
        "    for i in range(90, len(prices_series)):\n",
        "        window_prices = prices_series.iloc[i-90:i]\n",
        "        window_log_returns = calculate_log_returns(window_prices) * 100  # Scale log returns\n",
        "\n",
        "        model = arch_model(window_log_returns, mean='constant', vol='GARCH', p=1, q=1, rescale=False)\n",
        "        options = {\n",
        "        'maxiter': 1000,  # Nb d'itérations max\n",
        "        'ftol': 1e-6,     # Tolerance pour convergence\n",
        "        'disp': False     # Enlever les commentaires\n",
        "        }\n",
        "\n",
        "        #On fit le modèle \n",
        "        model_fit = model.fit(disp='off',options=options)\n",
        "\n",
        "        #On réalsie les prédictions (l'objet forecast contient les moyennes et volatilités prédites)\n",
        "        forecast = model_fit.forecast(horizon=forecast_horizon)\n",
        "\n",
        "        predicted_mean = forecast.mean.iloc[-1].values[0]\n",
        "        predicted_volatility = forecast.variance.iloc[-1].values[0]\n",
        "\n",
        "        mean_predictions.append(predicted_mean)\n",
        "        volatility_predictions.append(predicted_volatility)\n",
        "        prediction_dates.append(prices_series.index[i])\n",
        "\n",
        "        # Calcul de la \"vraie\" volatilité à l'aide de la formule sigma_t**2=(r_t-m_t)**2\n",
        "        current_log_return = np.log(prices_series.iloc[i] / prices_series.iloc[i-1]) \n",
        "        true_volatility.append((current_log_return - predicted_mean) ** 2)\n",
        "\n",
        "    predictions_df = pd.DataFrame({\n",
        "        'Date': prediction_dates,\n",
        "        'Predicted_Mean': mean_predictions,\n",
        "        'Predicted_Volatility': volatility_predictions,\n",
        "        'True_Volatility': true_volatility\n",
        "    }).set_index('Date')\n",
        "\n",
        "    return predictions_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGZTc-WOa5Jn"
      },
      "outputs": [],
      "source": [
        "#Modèle LSTM \n",
        "def create_lstm_model():\n",
        "    model = models.Sequential([\n",
        "        Input(shape=(90, 1)),  # Define input shape here\n",
        "        layers.LSTM(256, return_sequences=True),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.LSTM(256, return_sequences=True),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.LSTM(256),\n",
        "        layers.Dense(128),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.ReLU(),\n",
        "        layers.Dense(1, kernel_regularizer=regularizers.l2(1e-4))  # Output is a single value (predicted variance)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgxy5b3ja5Jo",
        "outputId": "17607eb2-809d-4bf3-9792-469a5c8e782e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ADF Statistic: -2.2485887735694807\n",
            "p-value: 0.18908523296431257\n",
            "Warning: Log returns may not be stationary.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\idris\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\arch\\univariate\\base.py:768: ConvergenceWarning: The optimizer returned code 8. The message is:\n",
            "Positive directional derivative for linesearch\n",
            "See scipy.optimize.fmin_slsqp for code meaning.\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\idris\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\arch\\univariate\\base.py:768: ConvergenceWarning: The optimizer returned code 8. The message is:\n",
            "Positive directional derivative for linesearch\n",
            "See scipy.optimize.fmin_slsqp for code meaning.\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\idris\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\arch\\univariate\\base.py:768: ConvergenceWarning: The optimizer returned code 8. The message is:\n",
            "Positive directional derivative for linesearch\n",
            "See scipy.optimize.fmin_slsqp for code meaning.\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\idris\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\arch\\univariate\\base.py:768: ConvergenceWarning: The optimizer returned code 8. The message is:\n",
            "Positive directional derivative for linesearch\n",
            "See scipy.optimize.fmin_slsqp for code meaning.\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\idris\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\arch\\univariate\\base.py:768: ConvergenceWarning: The optimizer returned code 8. The message is:\n",
            "Positive directional derivative for linesearch\n",
            "See scipy.optimize.fmin_slsqp for code meaning.\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\idris\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\arch\\univariate\\base.py:768: ConvergenceWarning: The optimizer returned code 8. The message is:\n",
            "Positive directional derivative for linesearch\n",
            "See scipy.optimize.fmin_slsqp for code meaning.\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\idris\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\arch\\univariate\\base.py:768: ConvergenceWarning: The optimizer returned code 8. The message is:\n",
            "Positive directional derivative for linesearch\n",
            "See scipy.optimize.fmin_slsqp for code meaning.\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\idris\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\arch\\univariate\\base.py:768: ConvergenceWarning: The optimizer returned code 8. The message is:\n",
            "Positive directional derivative for linesearch\n",
            "See scipy.optimize.fmin_slsqp for code meaning.\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\idris\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\arch\\univariate\\base.py:768: ConvergenceWarning: The optimizer returned code 8. The message is:\n",
            "Positive directional derivative for linesearch\n",
            "See scipy.optimize.fmin_slsqp for code meaning.\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\idris\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\arch\\univariate\\base.py:768: ConvergenceWarning: The optimizer returned code 8. The message is:\n",
            "Positive directional derivative for linesearch\n",
            "See scipy.optimize.fmin_slsqp for code meaning.\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\idris\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\arch\\univariate\\base.py:768: ConvergenceWarning: The optimizer returned code 8. The message is:\n",
            "Positive directional derivative for linesearch\n",
            "See scipy.optimize.fmin_slsqp for code meaning.\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\idris\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\arch\\univariate\\base.py:768: ConvergenceWarning: The optimizer returned code 8. The message is:\n",
            "Positive directional derivative for linesearch\n",
            "See scipy.optimize.fmin_slsqp for code meaning.\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\idris\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\arch\\univariate\\base.py:768: ConvergenceWarning: The optimizer returned code 8. The message is:\n",
            "Positive directional derivative for linesearch\n",
            "See scipy.optimize.fmin_slsqp for code meaning.\n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\idris\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\arch\\univariate\\base.py:768: ConvergenceWarning: The optimizer returned code 8. The message is:\n",
            "Positive directional derivative for linesearch\n",
            "See scipy.optimize.fmin_slsqp for code meaning.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Calcul parallèle pour accélérer\n",
        "os.environ[\"OMP_NUM_THREADS\"] = \"8\"  \n",
        "os.environ[\"TF_NUM_INTRAOP_THREADS\"] = \"8\"\n",
        "os.environ[\"TF_NUM_INTEROP_THREADS\"] = \"8\"\n",
        "\n",
        "tf.config.threading.set_intra_op_parallelism_threads(8)\n",
        "tf.config.threading.set_inter_op_parallelism_threads(8)\n",
        "\n",
        "prices_series = X_dji_train\n",
        "predictions_df = garch_predictions(prices_series)\n",
        "\n",
        "true_volatility = predictions_df['True_Volatility'].values\n",
        "predicted_volatility = predictions_df['Predicted_Volatility'].values\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV_v5jR2CcZu",
        "outputId": "676a4cbc-842e-4a06-aa40-5dd557153927"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\idris\\AppData\\Local\\Temp\\ipykernel_16460\\3320194354.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  X = np.array([true_volatility[i-90:i] for i in range(90, len(true_volatility))], dtype=np.float32).reshape(-1, 90, 1)\n",
            "C:\\Users\\idris\\AppData\\Local\\Temp\\ipykernel_16460\\3320194354.py:8: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  y = np.vstack((true_volatility[90:], predicted_volatility[90:])).astype(np.float32).T  # Shape: [n_samples, 2]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: (4489, 90, 1), X dtype: float32\n",
            "y shape: (4489, 2), y dtype: float32\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "true_volatility = predictions_df['True_Volatility'].values\n",
        "predicted_volatility = predictions_df['Predicted_Volatility'].values\n",
        "\n",
        "# Preparer la data pour le LSTM\n",
        "X = np.array([true_volatility[i-90:i] for i in range(90, len(true_volatility))], dtype=np.float32).reshape(-1, 90, 1)\n",
        "y = np.vstack((true_volatility[90:], predicted_volatility[90:])).astype(np.float32).T  # Shape: [n_samples, 2]\n",
        "\n",
        "# Standardize X pour de meilleures perfs\n",
        "scaler_X = StandardScaler()\n",
        "X_scaled = np.array([scaler_X.fit_transform(seq.reshape(-1, 1)) for seq in X], dtype=np.float32)  # Reshape each sequence to 2D before scaling\n",
        "\n",
        "# Standardize y pour de meilleures perfs\n",
        "scaler_y = StandardScaler()\n",
        "y_scaled = scaler_y.fit_transform(y)  # Standardize y\n",
        "\n",
        "# Check \n",
        "print(f\"X shape: {X_scaled.shape}, X dtype: {X_scaled.dtype}\")\n",
        "print(f\"y shape: {y_scaled.shape}, y dtype: {y_scaled.dtype}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "CPRhMXADVvJs",
        "outputId": "1832354c-5bd1-4016-ce11-e7ceaaa3d56c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "141/141 [==============================] - 56s 346ms/step - loss: 0.8413\n",
            "Epoch 2/5\n",
            "141/141 [==============================] - 46s 329ms/step - loss: 0.2148\n",
            "Epoch 3/5\n",
            "141/141 [==============================] - 49s 346ms/step - loss: 0.1878\n",
            "Epoch 4/5\n",
            "141/141 [==============================] - 51s 365ms/step - loss: 0.1684\n",
            "Epoch 5/5\n",
            "141/141 [==============================] - 52s 367ms/step - loss: 0.1594\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2570666e2c0>"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "os.environ[\"OMP_NUM_THREADS\"] = \"8\"  \n",
        "os.environ[\"TF_NUM_INTRAOP_THREADS\"] = \"8\"\n",
        "os.environ[\"TF_NUM_INTEROP_THREADS\"] = \"8\"\n",
        "tf.config.threading.set_intra_op_parallelism_threads(8)\n",
        "tf.config.threading.set_inter_op_parallelism_threads(8)\n",
        "\n",
        "# Fonction coût utilisée lors de l'entraînement: \n",
        "\n",
        "def custom_loss(predicted_volatility, lambda_param=0.5):\n",
        "    predicted_volatility = tf.convert_to_tensor(predicted_volatility, dtype=tf.float32)\n",
        "\n",
        "    def loss(y_true, y_pred):\n",
        "        batch_size = tf.shape(y_true)[0]\n",
        "        predicted_vol_batch = predicted_volatility[:batch_size]  \n",
        "\n",
        "        mse = tf.keras.losses.MeanSquaredError()\n",
        "        mse_true = mse(y_true, y_pred)\n",
        "        mse_garch = mse(predicted_vol_batch, y_pred)\n",
        "\n",
        "        return lambda_param * mse_true + (1 - lambda_param) * mse_garch\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "# Initialisation et Compilation\n",
        "model = create_lstm_model()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005, clipnorm=1.0)  # Clip gradients with L2 norm threshold = 1.0\n",
        "model.compile(optimizer=optimizer, loss=custom_loss(y[:,1],lambda_param=0.01))\n",
        "\n",
        "# Entrainement\n",
        "model.fit(X, y_scaled[:, 0], epochs=5, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvNsvDZuFWg4"
      },
      "outputs": [],
      "source": [
        "# true_volatility = predictions_df['True_Volatility'].values\n",
        "# predicted_volatility = predictions_df['Predicted_Volatility'].values\n",
        "\n",
        "# # Preparing the data for LSTM\n",
        "# X = np.array([true_volatility[i-90:i] for i in range(90, len(true_volatility))]).reshape(-1, 90, 1)\n",
        "# y = np.vstack((true_volatility[90:], predicted_volatility[90:])).T\n",
        "\n",
        "# # Ensure X and y are of type float32\n",
        "# X = X.astype(np.float32)\n",
        "# y = y.astype(np.float32)\n",
        "\n",
        "# # Check shapes and types\n",
        "# print(f\"X shape: {X.shape}, X dtype: {X.dtype}\")\n",
        "# print(f\"y shape: {y.shape}, y dtype: {y.dtype}\")\n",
        "\n",
        "# # Model Initialization and Compilation\n",
        "# model = create_lstm_model()\n",
        "# model.compile(optimizer='adam', loss=\"mse\")\n",
        "\n",
        "# # Model Training\n",
        "# model.fit(X[:,1], y[:,1], epochs=100, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "AiT4tkJ8Fdhe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "141/141 [==============================] - 18s 116ms/step\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Predict standardized volatilities using the LSTM model\n",
        "y_pred_scaled = model.predict(X_scaled)  # Shape: (n_samples, 1)\n",
        "\n",
        "# Step 2: Inverse transform the predicted volatilities to the original scale\n",
        "# Create a dummy array with the same shape as y_scaled\n",
        "dummy_array = np.zeros_like(y_scaled)\n",
        "dummy_array[:, 1] = y_pred_scaled.flatten()  # Replace the second column with predicted volatilities\n",
        "\n",
        "# Inverse transform the dummy array\n",
        "y_pred_inverse = scaler_y.inverse_transform(dummy_array)  # Shape: (n_samples, 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           Date  Predicted_Mean  Predicted_Volatility GINN  Log_Return\n",
            "0    1994-09-20      823.590258                  10.878177  826.888466\n",
            "1    1994-09-21      823.627961                  10.731100  826.903796\n",
            "2    1994-09-22      823.659441                  10.582673  826.912543\n",
            "3    1994-09-23      823.685630                  10.432508  826.915569\n",
            "4    1994-09-26      823.709501                  10.290258  826.917345\n",
            "...         ...             ...                        ...         ...\n",
            "4484 2012-07-10      945.893304                 139.192093  957.691273\n",
            "4485 2012-07-11      945.835104                 139.378479  957.640970\n",
            "4486 2012-07-12      946.478102                 139.569885  958.292071\n",
            "4487 2012-07-13      945.721688                 139.795135  957.545187\n",
            "4488 2012-07-16      945.688446                 139.985580  957.519997\n",
            "\n",
            "[4489 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Extract the inverse-transformed predicted volatilities\n",
        "predicted_volatility_lstm_original_scale = y_pred_inverse[:, 1]  # Shape: (n_samples,)\n",
        "\n",
        "# Step 3: Combine predicted volatilities with corresponding means\n",
        "means = predictions_df['Predicted_Mean'].values[90:]  # Shape: (n_samples,)\n",
        "\n",
        "# Calculate log returns predicted\n",
        "log_returns_pred = means + np.sqrt(predicted_volatility_lstm_original_scale)\n",
        "\n",
        "output_df = pd.DataFrame({\n",
        "    'Date': predictions_df.index[90:],  # Use the corresponding dates\n",
        "    'Predicted_Mean': means,\n",
        "    'Predicted_Volatility GINN': predicted_volatility_lstm_original_scale,\n",
        "    'Log_Return': log_returns_pred\n",
        "})\n",
        "\n",
        "# Display the output DataFrame\n",
        "print(output_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "ocoDYglgF6Mm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[678329.44 678370.5  678421.06 ... 895825.5  894359.1  894334.06]\n"
          ]
        }
      ],
      "source": [
        "print(y[:,0])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tensorflow_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
